
Got the ZIP file of my Google Transactions today . 

Current goal -> 
Collect the relevant info from  this into a structured database like SQL database 


First set up the env for my Project . ( conda create --name finance python=3.10 )
I am using 3.10 version of python gfor versatile nature and good compatibility 


My env is named =  finance 


Now write the names of all the dependencies that we wnat to install inside our NEW  env (liek numpy pandas etc )
and also use -e. to isntall local pkg  thatwe are gonna write using Python OOPs 
and run it using  -> pip install -r requirements.txt 

#### IMP #####

( IMP if you are using -e . in  requoremnt.txt file , necessary to write a setup.py file 

info -> the pkg /module you install using pip ,are stored inside apython folder on C: / site-packages 
-> -e . ( e= editable packages   , . = HOEM DIR )

since all official modules  like numpy , pandas have metadta like {version ,author ,etc } , same way when we use -e . ,
we are saying to PIP  
that any function /class i will be using in this project( HOME DIR ) , should be treated same as a module like numpy pandas
and saved to site-packages folder .

so in same way to give OUR /MINE official meta- data logo to these local pkg  and
 treat it like any other official module for this or any other project in future , we use (-e .) 
 ( to add all fucntion IN  home dir. in editable mode (with metadata)  we add this metadata info. in  SETUP.PAY file) 
 whickh is like putting your OWN official seal on locla pkg YOU CREATE and saving it in your own env for curr/future USE 


)



Now I buuilt a web scraper (using bs4.BEuatifulSoup ) to scrap trnsactions from the Activity.html file ( form Google takeout ZIP )
and using Regex ( using grouping -> \d to fidn single digit , \w to find single word  + (1 or multiple instances )
*( 0 or multiple instance s, () to find such groups using regex , \s fr spaces in pattern) use re.search( pattern ,text .group(1))
.group(1) to extract conte isndie it )

### MISTAKES ###

I wrote all this in my locla repo first and then using git init tried to remote add origin but failed thrice , 
then made a enw repo first , cloned it on my lcoal , chanegd and added files , git add ,git vommit and then 
git psuh origin main (on main branch )-> 

IMP thing i observed 
git init and git remote add origin are NOT need if we are editing a cloned repo  . 

( FORM NOW ON ,i WILL FIRST MAKE REPO and then ONLY start editing it )



#### PUT MORE FOCUS FROM HERE ON #### 

Valdated Each column of the Datset by checking it Data types ndd DROPPIN ROWS whochwere IMPOSSINLE ( 30 Feb 2025 )

and then split the Datset and save dit insdie the Artifacts folder 


Wrote the model trianer COde 
